{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f4e4c1b",
   "metadata": {},
   "source": [
    "## Desafío N.1 - Datos Sintéticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ec6715",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "\n",
    "Simular datos sintéticos de manera automática para simularan una organización, los datos generados incluyen:\n",
    "\n",
    "- **Departamentos**: áreas funcionales como Finanzas, Marketing, IT, entre otras.  \n",
    "- **Puestos de trabajo**: roles típicos como Analista, Gerente, Técnico, etc.  \n",
    "- **Empleados**: personas con atributos como nombre, correo, teléfono, salario y fecha de contratación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef034eb6",
   "metadata": {},
   "source": [
    "### Tecnologías utilizadas\n",
    "\n",
    "| Herramienta | Propósito |\n",
    "|-------------|-----------|\n",
    "| `Faker`     | Generar datos sintéticos como nombres, correos, fechas y teléfonos |\n",
    "| `pandas`    | Crear y manipular estructuras de datos tipo DataFrame |\n",
    "| `random`    | Asignar valores aleatorios como salario, departamento y puesto |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c96dfa",
   "metadata": {},
   "source": [
    "### Estructura del código"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cd2837",
   "metadata": {},
   "source": [
    "El script se divide en tres bloques principales:\n",
    "\n",
    "1. **Generación de departamentos**\n",
    "   - Se define una lista fija de nombres de departamentos.\n",
    "   - Se crea un ID secuencial para identificar cada departamento.\n",
    "   - Se asigna un `department_id` secuencial y una ciudad generada aleatoriamente como ubicación (`location`) usando `Faker`.\n",
    "\n",
    "```python\n",
    "departments = [\"Tecnología\", \"Finanzas\", \"Recursos Humanos\", \"Marketing\", \"Operaciones\"]\n",
    "departments_df = pd.DataFrame({\n",
    "    \"department_id\": range(1, len(departments) + 1),\n",
    "    \"department_name\": departments,\n",
    "    \"location\": [fake.city() for _ in departments]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e335bf76",
   "metadata": {},
   "source": [
    "2. **Generación de puestos de trabajo**\n",
    "    - Se fijan puestos de trabajo para los departamentos creados.\n",
    "    - Se crea un ID secuencial (`job_id`) para identificar cada puesto.\n",
    "    - Se asgina n salario mínimo (`min_salary`) generado aleatoriamente entre 2.000.000 y 5.000.000.\n",
    "    - Se asigna un máximo (`max_salary`) generado aleatoriamente entre 5.000.001 y 10.000.000.\n",
    "    \n",
    "```python\n",
    "puestos = [\"Analista\", \"Gerente\", \"Asistente\", \"Director\", \"Técnico\"]\n",
    "df_puestos = pd.DataFrame({\n",
    "    \"job_id\": range(1, len(puestos) + 1),\n",
    "    \"job_title\": puestos,\n",
    "    \"min_salary\": [random.randint(2_000_000, 5_000_000) for _ in puestos],\n",
    "    \"max_salary\": [random.randint(5_000_001, 10_000_000) for _ in puestos]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9916a8db",
   "metadata": {},
   "source": [
    "3. **Empleados**\n",
    "\n",
    "Se generan 50 empleados con atributos realistas utilizando la librería `Faker`. Cada empleado incluye:\n",
    "\n",
    "- Un `employee_id` único.\n",
    "- Nombre (`first_name`) y apellido (`last_name`).\n",
    "- Correo electrónico generado a partir del nombre y apellido.\n",
    "- Número de teléfono simulado.\n",
    "- Fecha de contratación aleatoria entre hoy y hace 5 años.\n",
    "- Salario aleatorio entre 2.000.000 y 10.000.000.\n",
    "- Asociación aleatoria a un departamento (`department_id`) y a un puesto (`job_id`).\n",
    "\n",
    "```python\n",
    "dominios = [\"gmail.com\", \"outlook.com\", \"yahoo.es\", \"empresa.com\", \"correo.com\"]\n",
    "empleados = []\n",
    "for i in range(1, 1001): \n",
    "    first_name = fake.first_name()\n",
    "    last_name = fake.last_name()\n",
    "    email = f\"{first_name.lower()}.{last_name.lower()}@{random.choice(dominios)}\"\n",
    "    job_id = random.randint(1, len(puestos))\n",
    "    min_sal = df_puestos.loc[df_puestos[\"job_id\"] == job_id, \"min_salary\"].values[0]\n",
    "    max_sal = df_puestos.loc[df_puestos[\"job_id\"] == job_id, \"max_salary\"].values[0]\n",
    "    salary = round(random.uniform(min_sal, max_sal))\n",
    "    empleados.append({\n",
    "        \"employee_id\": i,\n",
    "        \"first_name\": first_name,\n",
    "        \"last_name\": last_name,\n",
    "        \"email\": email,\n",
    "        \"phone_number\": fake.phone_number(),\n",
    "        \"department_id\": random.randint(1, len(departamentos)),\n",
    "        \"job_id\": job_id,\n",
    "        \"salary\": salary,\n",
    "        \"hire_date\": fake.date_between(start_date=\"-5y\", end_date=\"today\")\n",
    "    })\n",
    "\n",
    "df_empleados = pd.DataFrame(empleados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0951e8a3",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b52f6",
   "metadata": {},
   "source": [
    "## Desafío N.2 - Almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3442529",
   "metadata": {},
   "source": [
    "Los tres DataFrames generados fueron almacenados en formato **CSV** y **Parquet** dentro de la carpeta `data/`.\n",
    "\n",
    "#### Formatos utilizados\n",
    "\n",
    "| Formato  | Ventajas principales |\n",
    "|----------|----------------------|\n",
    "| CSV      | Simple, legible, ampliamente compatible con motores como excel, powerbi, pentaho |\n",
    "| Parquet  | Eficiente en espacio, rápido para lectura/escritura, ideal para grandes volúmenes, perfecto para ser consumido por servicion en la nube como Azure Databricks |\n",
    "\n",
    "#### Archivos generados\n",
    "\n",
    "- `data/departments.csv`  \n",
    "- `data/jobs.csv`  \n",
    "- `data/employees.csv`  \n",
    "- `data/departments.parquet`  \n",
    "- `data/jobs.parquet`  \n",
    "- `data/employees.parquet`\n",
    "\n",
    "#### Justificación\n",
    "\n",
    "Se eligió **Parquet** como formato complementario por las siguientes razones:\n",
    "\n",
    "- Es altamente eficiente en almacenamiento y velocidad de lectura.\n",
    "- Utiliza un formato **columnar**, lo que permite acceder rápidamente a columnas específicas sin cargar todo el archivo.\n",
    "- Está optimizado para entornos de análisis en la nube como **Azure**, **AWS**, **Databricks** y **BigQuery**.\n",
    "- Es ideal para **almacenamiento distribuido**, especialmente en arquitecturas orientadas a Big Data y Data Lakes.\n",
    "\n",
    "Por estas ventajas, Parquet complementa al formato CSV, ofreciendo una solución más robusta para procesamiento escalable y análisis avanzado.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
